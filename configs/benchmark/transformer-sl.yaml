# @package _global_
policy:
  policy: transformer
  embed_dim: 128
  num_heads: 8 
  num_encoder_layers: 6

model:
  algorithm: sl
  rollout_batch_size: 30
  mini_batch_size: 1000
  inner_epochs: 5

train:
  epochs: 30
  batch_size: 100
  dataset_size: 100
